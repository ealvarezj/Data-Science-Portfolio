{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Using tests to win Jeopardy\n",
    "\n",
    "In this notebook we are going to explore the [`Jeopardy`](https://www.reddit.com/r/datasets/comments/1uyd0t/200000_jeopardy_questions_in_a_json_file) dataset. Containing over 20000 questions and answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import chi2_contingency\n",
    "from scipy.stats import chisquare\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the data in\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Show Number</th>\n",
       "      <th>Air Date</th>\n",
       "      <th>Round</th>\n",
       "      <th>Category</th>\n",
       "      <th>Value</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>HISTORY</td>\n",
       "      <td>$200</td>\n",
       "      <td>For the last 8 years of his life, Galileo was ...</td>\n",
       "      <td>Copernicus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>ESPN's TOP 10 ALL-TIME ATHLETES</td>\n",
       "      <td>$200</td>\n",
       "      <td>No. 2: 1912 Olympian; football star at Carlisl...</td>\n",
       "      <td>Jim Thorpe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>EVERYBODY TALKS ABOUT IT...</td>\n",
       "      <td>$200</td>\n",
       "      <td>The city of Yuma in this state has a record av...</td>\n",
       "      <td>Arizona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>THE COMPANY LINE</td>\n",
       "      <td>$200</td>\n",
       "      <td>In 1963, live on \"The Art Linkletter Show\", th...</td>\n",
       "      <td>McDonald's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>EPITAPHS &amp; TRIBUTES</td>\n",
       "      <td>$200</td>\n",
       "      <td>Signer of the Dec. of Indep., framer of the Co...</td>\n",
       "      <td>John Adams</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Show Number    Air Date      Round                         Category  Value  \\\n",
       "0         4680  2004-12-31  Jeopardy!                          HISTORY   $200   \n",
       "1         4680  2004-12-31  Jeopardy!  ESPN's TOP 10 ALL-TIME ATHLETES   $200   \n",
       "2         4680  2004-12-31  Jeopardy!      EVERYBODY TALKS ABOUT IT...   $200   \n",
       "3         4680  2004-12-31  Jeopardy!                 THE COMPANY LINE   $200   \n",
       "4         4680  2004-12-31  Jeopardy!              EPITAPHS & TRIBUTES   $200   \n",
       "\n",
       "                                            Question      Answer  \n",
       "0  For the last 8 years of his life, Galileo was ...  Copernicus  \n",
       "1  No. 2: 1912 Olympian; football star at Carlisl...  Jim Thorpe  \n",
       "2  The city of Yuma in this state has a record av...     Arizona  \n",
       "3  In 1963, live on \"The Art Linkletter Show\", th...  McDonald's  \n",
       "4  Signer of the Dec. of Indep., framer of the Co...  John Adams  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jp = pd.read_csv('jeopardy.csv')\n",
    "\n",
    "jp.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Show Number', ' Air Date', ' Round', ' Category', ' Value',\n",
      "       ' Question', ' Answer'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(jp.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the column names have empty spaces in them, let's correct that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Show Number', 'Air Date', 'Round', 'Category', 'Value', 'Question',\n",
       "       'Answer'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jp.columns = jp.columns.str.strip()\n",
    "jp.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are going to work with the questions and answers. It is alway important to normalize the data. In this case means lowecasing and removig punctuations. Also the Value colum is not numeric so we will need to convert it to an int. The Air Time column can be also converted to a `Datetime` object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_tex(string):\n",
    "    '''\n",
    "    This function strips all non alphanumeric characters and lower them\n",
    "    '''\n",
    "    string = string.lower()\n",
    "    string = re.sub('[^A-Za-z0-9\\s]', \"\", string)\n",
    "    string = re.sub('\\s+', \" \", string)\n",
    "    return string\n",
    "\n",
    "def normalize_values(value):\n",
    "    '''\n",
    "    This function tries to transform the value column to an int, by removing all non numeric characters\n",
    "    '''\n",
    "    value = re.sub('[^0-9]', \"\", value)\n",
    "    try:\n",
    "        value = int(value)\n",
    "    except Exception:\n",
    "        value = 0\n",
    "        \n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "jp['clean_question'] = jp.Question.apply(normalize_tex)\n",
    "jp['clean_answer'] = jp.Answer.apply(normalize_tex)\n",
    "jp['clean_values'] = jp.Value.apply(normalize_values)\n",
    "jp['Air Date'] = pd.to_datetime(jp['Air Date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_terms(row):\n",
    "    split_answer = row['clean_answer'].split()\n",
    "    split_question = row['clean_question'].split()\n",
    "    \n",
    "    match_count = 0\n",
    "    if 'the' in split_answer:\n",
    "        split_answer.remove('the')\n",
    "    if len(split_answer) == 0:\n",
    "        return  0\n",
    "    for word in split_answer:\n",
    "        if word in split_question:\n",
    "            match_count += 1\n",
    "    return match_count/len(split_answer)  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "jp['answer_in_question'] = jp.apply(count_terms, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.059001965249777744"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jp.answer_in_question.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The answer only appears 6% of the time in the question. So the probability of getting the right answer by just looking at the question is pretty low. You will need to learn :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6876974695057736"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "question_overlap = list()\n",
    "terms_used = set()\n",
    "\n",
    "jp.sort_values(by='Air Date', inplace=True)\n",
    "\n",
    "for index, row in jp.iterrows():\n",
    "    split_question = row['clean_question'].split(\" \")\n",
    "    split_question = [word for word in split_question if len(word) > 5]\n",
    "    \n",
    "    match_count = 0\n",
    "    \n",
    "    for word in split_question:\n",
    "        if word in terms_used:\n",
    "            match_count += 1\n",
    "    for word in split_question:\n",
    "        terms_used.add(word)\n",
    "    if len(split_question) > 0:\n",
    "        match_count /= len(split_question)\n",
    "    question_overlap.append(match_count)\n",
    "        \n",
    "        \n",
    "jp['question_overlap'] = question_overlap\n",
    "\n",
    "jp['question_overlap'].mean()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see that about 70\\% of question words overlap, buit since they are not exactly the same, we cannot conclude that the probability of getting the same queation is so high, maybe some words and concepts are just formulated differently"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Low value vs high value questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_value (row):\n",
    "    if row['clean_values'] > 800:\n",
    "        value = 1\n",
    "    else:\n",
    "        value = 0\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "jp['high_value'] = jp.apply(classify_value, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_type(word):\n",
    "    low_count = 0\n",
    "    high_count = 0\n",
    "    \n",
    "    for i, row in jp.iterrows():\n",
    "        if word in row['clean_question'].split(\" \"):\n",
    "            if row['high_value'] == 1:\n",
    "                high_count += 1\n",
    "            else:\n",
    "                low_count += 1\n",
    "    return high_count, low_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "comparison_terms = random.sample(list(terms_used), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "observed_expected = list()\n",
    "\n",
    "for obs in comparison_terms:\n",
    "    high_count, low_count = count_type(obs)\n",
    "    observed_expected.append([high_count, low_count])\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 0],\n",
       " [0, 1],\n",
       " [5, 19],\n",
       " [9, 32],\n",
       " [0, 1],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [2, 1],\n",
       " [0, 1]]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observed_expected\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Power_divergenceResult(statistic=2.487792117195675, pvalue=0.11473257634454047),\n",
       " Power_divergenceResult(statistic=0.401962846126884, pvalue=0.5260772985705469),\n",
       " Power_divergenceResult(statistic=0.7209745992373746, pvalue=0.395824408918502),\n",
       " Power_divergenceResult(statistic=0.9053930713848508, pvalue=0.3413397346165769),\n",
       " Power_divergenceResult(statistic=0.401962846126884, pvalue=0.5260772985705469),\n",
       " Power_divergenceResult(statistic=0.401962846126884, pvalue=0.5260772985705469),\n",
       " Power_divergenceResult(statistic=2.487792117195675, pvalue=0.11473257634454047),\n",
       " Power_divergenceResult(statistic=0.401962846126884, pvalue=0.5260772985705469),\n",
       " Power_divergenceResult(statistic=2.1177104383031944, pvalue=0.14560406868263753),\n",
       " Power_divergenceResult(statistic=0.401962846126884, pvalue=0.5260772985705469)]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "high_value_count = jp[jp['high_value'] == 1].shape[0]\n",
    "low_value_count = jp[jp['high_value'] == 0].shape[0]\n",
    "\n",
    "chi_squared = list()\n",
    "\n",
    "for lst in observed_expected:\n",
    "    total = sum(lst)\n",
    "    total_prop = total / jp.shape[0]\n",
    "    expected_high = total_prop * high_value_count\n",
    "    expected_low  = total_prop * low_value_count\n",
    "    \n",
    "    observed = np.array(lst)\n",
    "    expected = np.array([expected_high, expected_low])\n",
    "    chi_squared.append(chisquare(observed, expected))\n",
    "    \n",
    "chi_squared\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the result above we can see that the smalles p_val in our sample was 11\\% which means non of our samples is statistically significant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
